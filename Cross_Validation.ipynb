{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaidatta71/Chatbot/blob/main/Cross_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-f4f3ef0fa8eec903",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "iIk4187GcwWT"
      },
      "source": [
        "This assignment focuses on solving a specific regression problem using basic cross-validation with a train/test/validation split. In addition to using the methods explored, this assignment also aims to familiarize you with further utilities for data transformation including, the OneHotEncoder and OrdinalEncoder along with their use in a make_column_transformer.\n",
        "\n",
        "The operations of encoding categorical features will be introduced using sklearn. This will allow you to streamline your model-building pipelines. Depending on whether a string type feature is ordinal or categorical we want to encode differently. The OrdinalEncoder will be used to encode features that do not need to be binarized due to an underlying order, and OneHotEncoder for categorical features (as a similar approach to that of the .get_dummies() method in pandas). By the end of the assignment, you will see how to chain multiple feature encoding methods together, including the earlier PolynomialFeatures for numeric features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJSOg_5JcwWU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-4816d0d701347e37",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "HiBkIoyFcwWV"
      },
      "source": [
        "### Three Synthetic Datasets\n",
        "\n",
        "Below, polynomial functions of different degrees were created, and noise was added to generate three basic synthetic datasets.  The relationships are then plotted. They are of varying true complexity -- cubic, quadratic, and quintic (polynomials of degree 5).  Your goal is to use cross-validation to determine the appropriate model and examine its mean squared error on a set of validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_YhQreXcwWV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/synthetic_8.6.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsBxjdhecwWV",
        "outputId": "8d024a9e-5953-42a1-959a-7762dd49268c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-0.522368</td>\n",
              "      <td>5.698300</td>\n",
              "      <td>3.880352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.929293</td>\n",
              "      <td>-0.711336</td>\n",
              "      <td>-0.257942</td>\n",
              "      <td>8.643553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.858586</td>\n",
              "      <td>-4.759917</td>\n",
              "      <td>12.775233</td>\n",
              "      <td>6.116844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.787879</td>\n",
              "      <td>-10.255472</td>\n",
              "      <td>22.140157</td>\n",
              "      <td>12.493956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.717172</td>\n",
              "      <td>-3.503845</td>\n",
              "      <td>27.656110</td>\n",
              "      <td>10.335220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          x         y1         y2         y3\n",
              "0 -2.000000  -0.522368   5.698300   3.880352\n",
              "1 -1.929293  -0.711336  -0.257942   8.643553\n",
              "2 -1.858586  -4.759917  12.775233   6.116844\n",
              "3 -1.787879 -10.255472  22.140157  12.493956\n",
              "4 -1.717172  -3.503845  27.656110  10.335220"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6-ASmyqcwWW"
      },
      "source": [
        "**Plots of the Synthetic Datasets**\n",
        "\n",
        "<img src = 'images/quad.png'/><img src = 'images/quintic.png'/><img src = 'images/cubic.png'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-51eae9cb036d0cf0",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "f-mI5JyOcwWX"
      },
      "source": [
        "[Back to top](#Index:)\n",
        "\n",
        "### Problem 1\n",
        "\n",
        "#### Creating the Train and Test sets\n",
        "\n",
        "\n",
        "The scikit-learn library has a built-in function called `train_test_split` that accepts one or many arrays and returns a randomized split of the data.  Use the `train_test_split` function to split `x` and `y1` into train and test sets.  Set `random_state = 32` and create a test set using 30% of the data.  Assign your results as arrays to `X_train, X_test, y1_train, y1_test` below.  \n",
        "\n",
        "- In anticipation of using `LinearRegression` estimator, make sure your `X_train` and `X_test` are of shapes (70, 1) and (30, 1) respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-9434424b94dba3c0",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "BiLYHBYqcwWX",
        "outputId": "8a373408-2299-4d49-cae7-df23b2ea8d73"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y1_train, y1_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Answer check\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, X_train\u001b[38;5;241m.\u001b[39mshape, X_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mhead())\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "X_train, X_test, y1_train, y1_test = '', '', '', ''\n",
        "\n",
        "\n",
        "# Answer check\n",
        "print(df['x'].shape, X_train.shape, X_test.shape)\n",
        "print(X_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-de81ef2bbaab88ac",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "TprcspMLcwWX"
      },
      "source": [
        "[Back to top](#Index:)\n",
        "\n",
        "### Problem 2\n",
        "\n",
        "\n",
        "Use the `train_test_split` function to create similar splits of `y2` and `y3`.  Use the `random_state = 32` and create a test set using 30% of the data.   Assign your results to `y2_train`, `y2_test`, `y3_train`, and `y3_test` below.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-14a80d1dd8e68ebc",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "BUxzT3dQcwWX",
        "outputId": "e3b7528c-ea63-4370-9030-4cb49d0715c1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m y3_train, y3_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Answer check\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, y2_train\u001b[38;5;241m.\u001b[39mshape, y2_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(y2_train\u001b[38;5;241m.\u001b[39mhead())\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "y2_train, y2_test, y3_train, y3_test  = '', ''\n",
        "\n",
        "\n",
        "\n",
        "# Answer check\n",
        "print(df['y2'].shape, y2_train.shape, y2_test.shape)\n",
        "print(y2_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-d22e18e493c7a842",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "hGf-V828cwWY"
      },
      "source": [
        "[Back to top](#Index:)\n",
        "\n",
        "### Problem 3\n",
        "\n",
        "\n",
        "Use a `for` loop to loop over the values from one to 20. For each iteration `i`:\n",
        "\n",
        "- Use `Pipeline` to create a pipeline object. Inside the pipeline object define a a tuple where the first element is a string identifier `pfeat` and the second element is an instance of `PolynomialFeatures` of degree `i` with `include_bias = False`. Inside the pipeline define another tuple where the first element is a string identifier `linreg`, and the second element is an instance of `LinearRegression`. Assign the pipeline object to the variable `pipe`.\n",
        "- Use the `fit` function on `pipe` to train your model on `X_train` and `y1_train`. Assign the result to `train_preds`.\n",
        "- Use the `predict` function on `pipe` to compute your prediction on `X_test`. Assign the result to `test_preds`.\n",
        "- Use the `mean_squared_error` function to calculate the MSE between `y1_train` and `train_preds`. Append your result to the `train_mses` list.\n",
        "- Use the `mean_squared_error` function to calculate the MSE between `y1_test` and `test_preds`. Append your result to the `test_mses` list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-22388d4a41b01c98",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "go8YDB0vcwWY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_mses = []\n",
        "test_mses = []\n",
        "\n",
        "#for complexity 1 - 20:\n",
        "\n",
        "    #create pipeline with PolynomialFeatures and LinearRegression\n",
        "    #remember to set include_bias = False\n",
        "\n",
        "    #fit pipeline on training data\n",
        "\n",
        "    #mse of training data\n",
        "\n",
        "    #mse of testing data\n",
        "\n",
        "best_model_complexity = ''\n",
        "\n",
        "\n",
        "# Answer check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BttFDPEvcwWY"
      },
      "source": [
        "Uncomment the code below to visualize the results of your model fitting.  Note that the data in `y1` were created from a quadratic model originally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR3oD4bXcwWY"
      },
      "outputs": [],
      "source": [
        "# print(f'The Complexity that minimized Test Error was: {test_mses.index(min(test_mses)) + 1}')\n",
        "# plt.plot(range(1, 21), train_mses, '--o', label = 'training error')\n",
        "# plt.plot(range(1, 21), test_mses, '--o', label = 'testing error')\n",
        "# plt.xticks(range(1, 21), range(1, 21))\n",
        "# plt.xlabel('Degree Complexity')\n",
        "# plt.ylabel('Mean Squared Error')\n",
        "# plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fbff2877fa3e10c1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        },
        "id": "O9ujBXpncwWY"
      },
      "source": [
        "[Back to top](#Index:)\n",
        "\n",
        "### Problem 4\n",
        "\n",
        "#### Write a function to determine best model complexity\n",
        "\n",
        "\n",
        "\n",
        "Complete the definition of the `simple_cross_validation` function according to the following instructions:\n",
        "\n",
        "\n",
        "Use a `for` loop to loop over the values from one to 20. For each iteration `i`:\n",
        "\n",
        "- Use `Pipeline` to create a pipeline object. Inside the pipeline object define a a tuple where the first element is a string identifier `pfeat` and the second element is an instance of `PolynomialFeatures` of degree `i` with `include_bias = False`. Inside the pipeline define another tuple where the first element is a string identifier `linreg`, and the second element is an instance of `LinearRegression`. Assign the pipeline object to the variable `pipe`.\n",
        "- Use the `fit` function on `pipe` to train your model on `X_train` and `y_train`.\n",
        "- Use the `predict` function on `pipe` to compute your prediction on `X_test`. Assign the result to `test_preds`.\n",
        "- Use the `mean_squared_error` function to calculate the MSE between `y_test` and `test_preds`. Assign your result to `test_mse`.\n",
        "- Use an `if` statement to check that `test_mse` is less than `best_mse`:\n",
        "    - If the condition is satisifed assign `test_mse` to `best_mse` and `pipe` to `best_pipe`.\n",
        "- Your function should return `best_pipe`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-68f0fca2c0aa71b4",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "id": "HgV_PZcXcwWY",
        "outputId": "5f407dc9-f76e-4097-a6ad-5da07ebfb98e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'memory': None,\n",
              " 'steps': [('pfeat', PolynomialFeatures(degree=10, include_bias=False)),\n",
              "  ('linreg', LinearRegression())],\n",
              " 'verbose': False,\n",
              " 'pfeat': PolynomialFeatures(degree=10, include_bias=False),\n",
              " 'linreg': LinearRegression(),\n",
              " 'pfeat__degree': 10,\n",
              " 'pfeat__include_bias': False,\n",
              " 'pfeat__interaction_only': False,\n",
              " 'pfeat__order': 'C',\n",
              " 'linreg__copy_X': True,\n",
              " 'linreg__fit_intercept': True,\n",
              " 'linreg__n_jobs': None,\n",
              " 'linreg__normalize': 'deprecated',\n",
              " 'linreg__positive': False}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "def simple_cross_validation(X_train, y_train, X_test, y_test):\n",
        "    best_pipe = None #placeholder for best model\n",
        "    best_mse = np.inf #set best mse to infinity to begin\n",
        "    #for complexity 1 - 20:\n",
        "\n",
        "        #create pipeline with PolynomialFeatures and LinearRegression\n",
        "        #remember to set include_bias = False\n",
        "\n",
        "        #fit pipeline on training data\n",
        "\n",
        "        #mse of testing data\n",
        "\n",
        "        #if mse is best -- set best_pipe = pipe\n",
        "\n",
        "        #return best pipeline\n",
        "\n",
        "\n",
        "\n",
        "best_model = simple_cross_validation(X_train, y2_train, X_test, y2_test)\n",
        "best_model.get_params() #should be degree = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypt4jFutcwWY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb965aEYcwWY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xggllFLTcwWY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}